{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd3e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import kmapper as km\n",
    "import sklearn\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import signal\n",
    "import time\n",
    "import random\n",
    "from networkx.algorithms.similarity import graph_edit_distance\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801e8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k(spectrum, minimum_energy = 0.9):\n",
    "    running_total = 0.0 \n",
    "    \n",
    "    total = sum(spectrum)\n",
    "    if total == 0.0:\n",
    "        return len(spectrum)\n",
    "    for i in range(len(spectrum)):\n",
    "        running_total += spectrum[i]\n",
    "        if running_total / total >= minimum_energy:\n",
    "            return i + 1\n",
    "    return len(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d637af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(graph1,graph2):\n",
    "    laplacian1 = nx.spectrum.laplacian_spectrum(graph1)\n",
    "    laplacian2 = nx.spectrum.laplacian_spectrum(graph2)\n",
    "    \n",
    "    k1 = select_k(laplacian1)\n",
    "    k2 = select_k(laplacian2)\n",
    "    k = min(k1, k2) #k are different between the two graphs, then use the smaller one.\n",
    "    similarity = sum((laplacian1[:k] - laplacian2[:k])**2) #sum of the squared differences between the largest k eigenvalues\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b94fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_graph_features(graph):\n",
    "    pr = nx.pagerank(graph,0.9)\n",
    "    dc = nx.degree_centrality(graph)\n",
    "    cc = nx.closeness_centrality(graph)\n",
    "    bx = nx.betweenness_centrality(graph)\n",
    "    c = nx.clustering(graph)\n",
    "    \n",
    "    #create list for each features\n",
    "    pr_list =  [i for i in pr.values()]\n",
    "    dc_list =  [i for i in dc.values()]\n",
    "    cc_list =  [i for i in cc.values()]\n",
    "    bx_list =  [i for i in bx.values()]\n",
    "    c_list =  [i for i in c.values()]\n",
    "    d_list = [val for (node, val) in graph.degree()]\n",
    "    data = np.column_stack((pr_list,dc_list,cc_list,bx_list,c_list,d_list))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4dee6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TDA_transformation(data):\n",
    "    Xfilt = data\n",
    "    mapper = km.KeplerMapper()\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    Xfilt = scaler.fit_transform(Xfilt)\n",
    "    lens = mapper.fit_transform(Xfilt, projection=sklearn.manifold.TSNE())\n",
    "    cls = 5  # We use cls= 5\n",
    "\n",
    "    graph = mapper.map(lens,Xfilt,clusterer=sklearn.cluster.KMeans(n_clusters=cls,random_state=1618033),\n",
    "        cover=km.Cover(n_cubes=2, perc_overlap=0.3))\n",
    "    return km.to_nx(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a14420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_to_graph(graph,p):\n",
    "    new_node = graph.number_of_nodes() + 1\n",
    "    graph.add_node(new_node)\n",
    "    existing_nodes = list(graph.nodes())[:-1]  # Exclude the new node\n",
    "    for existing_node in existing_nodes:\n",
    "        if random.random() < p:  \n",
    "            graph.add_edge(new_node, existing_node)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e8060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_least_degree_node(graph):\n",
    "    degrees = graph.degree()\n",
    "    min_degree_node = min(degrees, key=lambda x: x[1])[0]\n",
    "    # Remove the node with the minimum degree\n",
    "    graph.remove_node(min_degree_node)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e9b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_add_new_edge(graph):\n",
    "    node_num = graph.number_of_nodes()\n",
    "    node1 = random.randint(1,node_num)\n",
    "    node2 = random.randint(1,node_num)\n",
    "    while graph.has_edge(node1,node2) or node1 == node2 :\n",
    "        node1 = random.randint(1,node_num)\n",
    "        node2 = random.randint(1,node_num)\n",
    "    graph.add_edge(node1,node2)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d0f40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_remove_edge(graph):\n",
    "    random_edge = random.choice(list(graph.edges()))\n",
    "    # Remove the randomly selected edge\n",
    "    graph.remove_edge(*random_edge)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d19b6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_generator(original_graph, node, edge,p):\n",
    "    new_graph = original_graph.copy()\n",
    "    if node < 0:\n",
    "        for i in range(abs(node)):\n",
    "            new_graph = remove_least_degree_node(new_graph)\n",
    "    elif node > 0:\n",
    "        for i in range(abs(node)):\n",
    "            new_graph = add_node_to_graph(new_graph,p)\n",
    "    \n",
    "    if edge < 0:\n",
    "        for i in range(abs(edge)):\n",
    "            new_graph = random_remove_edge(new_graph)\n",
    "    elif edge >0:\n",
    "        for i in range(abs(edge)):\n",
    "            new_graph = random_add_new_edge(new_graph)\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9bc0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_original_average_similarity_for_hop(graph, hop,p):\n",
    "    counter = 0\n",
    "    sum = 0\n",
    "    for i in range(-hop,hop + 1):\n",
    "        for j in range(-hop,hop + 1):\n",
    "            if (i == -hop or i == hop or j == -hop or j == hop):\n",
    "                neighbour = graph_generator(graph,j,i,p)\n",
    "                score = calculate_similarity(graph, neighbour)\n",
    "                sum += score\n",
    "                counter += 1\n",
    "    return sum/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff6ae733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_TDA_average_similarity_for_hop(graph, hop,p):\n",
    "    counter = 0\n",
    "    sum = 0\n",
    "    for i in range(-hop,hop + 1):\n",
    "        for j in range(-hop,hop + 1):\n",
    "            if (i == -hop or i == hop or j == -hop or j == hop):\n",
    "                neighbour = graph_generator(graph,j,i,p)\n",
    "                TDA_graph = TDA_transformation(extract_graph_features(graph))\n",
    "                TDA_neighbour = TDA_transformation(extract_graph_features(neighbour))\n",
    "                score = calculate_similarity(TDA_graph, TDA_neighbour)\n",
    "                sum += score\n",
    "                counter += 1\n",
    "    return sum/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e77d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_both_average_similarity_for_hop(graph, hop,p):\n",
    "    counter = 0\n",
    "    sum_original = 0\n",
    "    sum_TDA = 0\n",
    "    for i in range(-hop,hop + 1):\n",
    "        for j in range(-hop,hop + 1):\n",
    "            if (i == -hop or i == hop or j == -hop or j == hop):\n",
    "                neighbour = graph_generator(graph,j,i,p)\n",
    "                TDA_graph = TDA_transformation(extract_graph_features(graph))\n",
    "                TDA_neighbour = TDA_transformation(extract_graph_features(neighbour))\n",
    "                \n",
    "                score_TDA = calculate_similarity(TDA_graph, TDA_neighbour)\n",
    "                score_original = calculate_similarity(graph, neighbour)\n",
    "                \n",
    "                sum_TDA += score_TDA\n",
    "                sum_original += score_original\n",
    "                counter += 1\n",
    "    return {\"TDA\": sum_TDA/counter,\"original\": sum_original/counter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8031a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hop_v1():\n",
    "    threshold = 50\n",
    "    n = random.randint(30,50)\n",
    "    reach_max = False\n",
    "    \n",
    "    p = round(random.uniform(60, 100))/100\n",
    "#     n = 30\n",
    "#     p = 0.6\n",
    "    reference_graph = nx.erdos_renyi_graph(n,p)\n",
    "    \n",
    "    TDA_average = 0\n",
    "    original_average = 0\n",
    "    \n",
    "    TDA_hop = 0\n",
    "    original_hop = 0\n",
    "    while (TDA_average <= threshold or original_average <= threshold) and TDA_hop < 15:\n",
    "        if(TDA_average <= threshold and original_average <= threshold):\n",
    "            TDA_hop += 1\n",
    "            original_hop += 1\n",
    "            result = calc_both_average_similarity_for_hop(reference_graph,TDA_hop ,p)\n",
    "            TDA_average = result['TDA']\n",
    "            original_average = result['original']\n",
    "            print(TDA_average,original_average)\n",
    "        elif(TDA_average <= threshold):\n",
    "            TDA_hop += 1\n",
    "            TDA_average = calc_TDA_average_similarity_for_hop(reference_graph,TDA_hop,p)\n",
    "            print(TDA_average)\n",
    "        elif(original_average <= threshold):\n",
    "            original_hop += 1\n",
    "            original_average = calc_original_average_similarity_for_hop(reference_graph,original_hop,p)\n",
    "            \n",
    "\n",
    "    if(reach_max):\n",
    "        return {\"Threshold\": threshold, \"n\":n,\"p\":p,\"last_TDA_average\": TDA_average, \"last_original_average\": original_average,\n",
    "               \"TDA_hop\": TDA_hop + \"+\",\"orginal_hop\":original_hop}\n",
    "    else:\n",
    "        return {\"Threshold\": threshold, \"n\":n,\"p\":p,\"last_TDA_average\": TDA_average, \"last_original_average\": original_average,\n",
    "               \"TDA_hop\": TDA_hop,\"orginal_hop\":original_hop}\n",
    "#     return {\"TDA_hop\":TDA_hop,\"orginnal\":original_hop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4619d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_average_for_hop(hop,ref_graph,n,p,delta_n,delta_p):\n",
    "    sum_original = 0\n",
    "    sum_TDA = 0\n",
    "    counter = 0\n",
    "    for i in range(-hop,hop + 1):\n",
    "        for j in range(-hop,hop + 1):\n",
    "            if (i == -hop or i == hop or j == -hop or j == hop):\n",
    "                neighbour = nx.erdos_renyi_graph(i*delta_n + n,j*delta_p + p)\n",
    "                \n",
    "                TDA_graph = TDA_transformation(extract_graph_features(ref_graph))\n",
    "                TDA_neighbour = TDA_transformation(extract_graph_features(neighbour))\n",
    "                \n",
    "                score_TDA = calculate_similarity(TDA_graph, TDA_neighbour)\n",
    "                score_original = calculate_similarity(ref_graph, neighbour)\n",
    "                \n",
    "                sum_TDA += score_TDA\n",
    "                sum_original += score_original\n",
    "                counter += 1\n",
    "    return {\"TDA\": sum_TDA/counter,\"original\": sum_original/counter}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f759128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TDA': 10.241611374972234, 'original': 48.233040939753295}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.erdos_renyi_graph(30,0.3)\n",
    "\n",
    "result = calc_average_for_hop(hop = 1,ref_graph = G,n = 30,p = 0.3,delta_n = 2,delta_p = 0.05)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6a0eefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TDA': 12.01539565964993, 'original': 207.2552312403941}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = calc_average_for_hop(hop = 2,ref_graph = G,n = 30,p = 0.3,delta_n = 2,delta_p = 0.05)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
